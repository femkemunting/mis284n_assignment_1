{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code if using Colab to run Selenium\n",
    "\n",
    "# Make sure to go to Runtime -> Change runtime and set GPU as hardware accelerator\n",
    "\n",
    "# !kill -9 -1 # Use this line to delete this VM and start a new one.\n",
    "# The above line deletes all files and folders from the current VM and allocates a new one.\n",
    "\n",
    "#Selenium is an open-source tool that automates web browsers.\n",
    "!pip install selenium\n",
    "!apt-get -q update   #Used to handle installation and removal of softwares and libraries\n",
    "!apt install -yq chromium-chromedriver #ChromeDriver is a separate executable that Selenium WebDriver uses to control Chrome.\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import manifold\n",
    "import string\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "import operator\n",
    "import io\n",
    "#WebDriver is a browser automation framework that works with open source APIs.\n",
    "#The framework operates by accepting commands, sending those commands to a browser, and interacting with applications.\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "#headless means running chrome with chrome.exe\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Create DataFrame\n",
    "comments = pd.DataFrame(columns = ['Date','user_id','comments'])\n",
    "\n",
    "\n",
    "#Srape Dates, Usernames, and Comments from most recent 115 pages (about 5000 comments)\n",
    "for i in range(320,436):\n",
    "\n",
    "    #address where scraping\n",
    "    webpage = 'https://forums.edmunds.com/discussion/2864/general/x/entry-level-luxury-performance-sedans/p' + str(i)\n",
    "    driver.get(webpage)\n",
    "\n",
    "    ids = driver.find_elements(By.XPATH,\"//*[contains(@id,'Comment_')]\")\n",
    "\n",
    "    comment_ids = []\n",
    "\n",
    "    for i in ids:\n",
    "        comment_ids.append(i.get_attribute('id'))\n",
    "\n",
    "    #check if there is a blockquote (used in replies to comments) and remove\n",
    "    for x in comment_ids:\n",
    "        try:\n",
    "            element = driver.find_elements(By.XPATH,'//*[@id=\"' + x +'\"]/div/div[3]/div/div[1]/blockquote')[0]\n",
    "            driver.execute_script(\"\"\"\n",
    "                var element = arguments[0];\n",
    "                element.parentNode.removeChild(element);\n",
    "                \"\"\", element)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for x in comment_ids:\n",
    "\n",
    "        #Extract dates from for each user on a page\n",
    "        user_date = driver.find_elements(By.XPATH,'//*[@id=\"' + x +'\"]/div/div[2]/div[2]/span[1]/a/time')[0]\n",
    "        date = user_date.get_attribute('title')\n",
    "\n",
    "        #Extract user ids from each user on a page\n",
    "        userid_element = driver.find_elements(By.XPATH,'//*[@id=\"' + x +'\"]/div/div[2]/div[1]/span[1]/a[2]')[0]\n",
    "        userid = userid_element.text\n",
    "\n",
    "        #Extract Message for each user on a page\n",
    "        user_message = driver.find_elements(By.XPATH,'//*[@id=\"' + x +'\"]/div/div[3]/div/div[1]')[0]\n",
    "\n",
    "        comment = user_message.text\n",
    "\n",
    "\n",
    "        #Adding date, userid and comment for each user in a dataframe\n",
    "        comments.loc[len(comments)] = [date,userid,comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the location as per the file destination you want it to be\n",
    "comments.to_csv('Edmunds_scraped2.0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If working from CSV instead of scraping originally, read in CSV\n",
    "comments = pd.read_csv('Edmunds_scraped2.0.csv',  index_col=0)\n",
    "\n",
    "#Nulls don't play well with the tokenizer, so drop nulls\n",
    "comments.dropna(inplace=True)\n",
    "comments.to_csv('Edmunds_scraped2.0.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
